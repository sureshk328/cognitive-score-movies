{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab690f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sures\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from unidecode import unidecode\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49fa7113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A terrible movie as everyone has said. What ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Finally watched this shocking movie last night...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I caught this film on AZN on cable. It sounded...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>It may be the remake of 1987 Autumn's Tale aft...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>My Super Ex Girlfriend turned out to be a plea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1\n",
       "5  A terrible movie as everyone has said. What ma...      0\n",
       "6  Finally watched this shocking movie last night...      1\n",
       "7  I caught this film on AZN on cable. It sounded...      0\n",
       "8  It may be the remake of 1987 Autumn's Tale aft...      1\n",
       "9  My Super Ex Girlfriend turned out to be a plea...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv(\"movie.csv\")\n",
    "df=movies.copy()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "739af2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('IMDB-Dataset.csv')\n",
    "#df = df[:10000]\n",
    "df.sentiment = df.sentiment.apply(lambda x: 1 if x=='positive' else 0)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea07eb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d84a07ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  sentiment\n",
      "0  One of the other reviewers has mentioned that ...          1\n",
      "1  A wonderful little production. <br /><br />The...          1\n",
      "2  I thought this was a wonderful way to spend ti...          1\n",
      "3  Basically there's a family where a little boy ...          0\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...          1\n",
      "5  Probably my all-time favorite movie, a story o...          1\n",
      "6  I sure would like to see a resurrection of a u...          1\n",
      "7  This show was an amazing, fresh & innovative i...          0\n",
      "8  Encouraged by the positive comments about this...          0\n",
      "9  If you like original gut wrenching laughter yo...          1\n",
      "                                              review  sentiment\n",
      "0  one of the other reviewers has mentioned that ...          1\n",
      "1  a wonderful little production the filming tech...          1\n",
      "2  i thought this was a wonderful way to spend ti...          1\n",
      "3  basically there s a family where a little boy ...          0\n",
      "4  petter mattei s love in the time of money is a...          1\n",
      "5  probably my all time favorite movie a story of...          1\n",
      "6  i sure would like to see a resurrection of a u...          1\n",
      "7  this show was an amazing fresh innovative idea...          0\n",
      "8  encouraged by the positive comments about this...          0\n",
      "9  if you like original gut wrenching laughter yo...          1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import html\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def lower(review):\n",
    "    return review.lower()\n",
    "\n",
    "def deletePunctuation(x):\n",
    "    return re.sub(r'[^\\w\\s]', ' ', x)\n",
    "\n",
    "def deleteSpaces(x):\n",
    "    return re.sub(r'\\s+', ' ', x)\n",
    "\n",
    "def unescape(x):\n",
    "    return html.unescape(x)\n",
    "\n",
    "def deleteHtmlTags(x):\n",
    "    return BeautifulSoup(x, \"lxml\").text\n",
    "\n",
    "print(df[:10])\n",
    "df.review = df.review.apply(lower)\n",
    "df.review = df.review.apply(deleteHtmlTags)\n",
    "df.review = df.review.apply(unidecode)\n",
    "df.review = df.review.apply(deletePunctuation)\n",
    "df.review = df.review.apply(unescape)\n",
    "df.review = df.review.apply(deleteSpaces)\n",
    "print(df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "606b51ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[one, review, mention, watch, 1, oz, episod, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "      <td>1</td>\n",
       "      <td>[wonder, littl, product, film, techniqu, veri,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "      <td>[thought, wonder, way, spend, time, hot, summe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there s a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[basic, famili, littl, boy, jake, think, zombi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei s love in the time of money is a...</td>\n",
       "      <td>1</td>\n",
       "      <td>[petter, mattei, love, time, money, visual, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>1</td>\n",
       "      <td>[thought, movi, right, good, job, creativ, ori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "      <td>0</td>\n",
       "      <td>[bad, plot, bad, dialogu, bad, act, idiot, dir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>0</td>\n",
       "      <td>[cathol, taught, parochi, elementari, school, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i m going to have to disagree with the previou...</td>\n",
       "      <td>0</td>\n",
       "      <td>[go, disagre, previous, comment, side, maltin,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>0</td>\n",
       "      <td>[one, expect, star, trek, movi, high, art, fan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment  \\\n",
       "0      one of the other reviewers has mentioned that ...          1   \n",
       "1      a wonderful little production the filming tech...          1   \n",
       "2      i thought this was a wonderful way to spend ti...          1   \n",
       "3      basically there s a family where a little boy ...          0   \n",
       "4      petter mattei s love in the time of money is a...          1   \n",
       "...                                                  ...        ...   \n",
       "49995  i thought this movie did a down right good job...          1   \n",
       "49996  bad plot bad dialogue bad acting idiotic direc...          0   \n",
       "49997  i am a catholic taught in parochial elementary...          0   \n",
       "49998  i m going to have to disagree with the previou...          0   \n",
       "49999  no one expects the star trek movies to be high...          0   \n",
       "\n",
       "                                                 stemmed  \n",
       "0      [one, review, mention, watch, 1, oz, episod, h...  \n",
       "1      [wonder, littl, product, film, techniqu, veri,...  \n",
       "2      [thought, wonder, way, spend, time, hot, summe...  \n",
       "3      [basic, famili, littl, boy, jake, think, zombi...  \n",
       "4      [petter, mattei, love, time, money, visual, st...  \n",
       "...                                                  ...  \n",
       "49995  [thought, movi, right, good, job, creativ, ori...  \n",
       "49996  [bad, plot, bad, dialogu, bad, act, idiot, dir...  \n",
       "49997  [cathol, taught, parochi, elementari, school, ...  \n",
       "49998  [go, disagre, previous, comment, side, maltin,...  \n",
       "49999  [one, expect, star, trek, movi, high, art, fan...  \n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "df[\"stemmed\"] = df.review.apply(lambda x: [stemmer.stem(y) for y in x.split() if stemmer.stem(y) not in (stop)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "343d3e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movi       103216\n",
       "film        95837\n",
       "one         55427\n",
       "like        45187\n",
       "time        31945\n",
       "            ...  \n",
       "possibi         1\n",
       "sme             1\n",
       "235th           1\n",
       "tvcat           1\n",
       "movie8          1\n",
       "Length: 72969, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(np.hstack(df.stemmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c76226b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movi', 'film', 'one', 'like', 'time', 'good', 'make', 'charact', 'see', 'get', 'watch', 'veri', 'even', 'stori', 'would', 'onli', 'realli', 'well', 'scene', 'look']\n"
     ]
    }
   ],
   "source": [
    "noOfWords = 10000\n",
    "vocab_df = pd.value_counts(np.hstack(df.stemmed)).keys()\n",
    "vocabulary = list(vocab_df[:noOfWords])\n",
    "print(vocabulary[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b6cfe18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Indices Dimension: 10002\n"
     ]
    }
   ],
   "source": [
    "token_indices = dict((t, i + 2) for i, t in enumerate(vocabulary))\n",
    "indices_token = dict((i + 2, t) for i, t in enumerate(vocabulary))\n",
    "\n",
    "indices_token[0] = 'UNK'\n",
    "token_indices['UNK'] = 0\n",
    "\n",
    "indices_token[1] = 'PAD'\n",
    "token_indices['PAD'] = 1\n",
    "\n",
    "print('Token Indices Dimension:', len(indices_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3156160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data: 5000\n",
      "Train Data: 40000\n",
      "Validation Data: 5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33553</th>\n",
       "      <td>i really liked this summerslam due to the look...</td>\n",
       "      <td>1</td>\n",
       "      <td>[realli, like, summerslam, due, look, arena, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9427</th>\n",
       "      <td>not many television shows appeal to quite as m...</td>\n",
       "      <td>1</td>\n",
       "      <td>[mani, televis, show, appeal, quit, mani, diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>the film quickly gets to a major chase scene w...</td>\n",
       "      <td>0</td>\n",
       "      <td>[film, quick, get, major, chase, scene, ever, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12447</th>\n",
       "      <td>jane austen would definitely approve of this o...</td>\n",
       "      <td>1</td>\n",
       "      <td>[jane, austen, would, definit, approv, one, gw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39489</th>\n",
       "      <td>expectations were somewhat high for me when i ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[expect, somewhat, high, went, see, movi, thou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment  \\\n",
       "33553  i really liked this summerslam due to the look...          1   \n",
       "9427   not many television shows appeal to quite as m...          1   \n",
       "199    the film quickly gets to a major chase scene w...          0   \n",
       "12447  jane austen would definitely approve of this o...          1   \n",
       "39489  expectations were somewhat high for me when i ...          0   \n",
       "\n",
       "                                                 stemmed  \n",
       "33553  [realli, like, summerslam, due, look, arena, c...  \n",
       "9427   [mani, televis, show, appeal, quit, mani, diff...  \n",
       "199    [film, quick, get, major, chase, scene, ever, ...  \n",
       "12447  [jane, austen, would, definit, approv, one, gw...  \n",
       "39489  [expect, somewhat, high, went, see, movi, thou...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.1, random_state = 42)\n",
    "\n",
    "print('Test Data:', len(test_df))\n",
    "train_df, valid_df = train_test_split(train_df, test_size=(0.1/0.9), random_state = 42)\n",
    "\n",
    "print('Train Data:', len(train_df))\n",
    "print('Validation Data:', len(valid_df))\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c150f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sentences(data, token_indices, one_hot = False):\n",
    "    vectorized = []\n",
    "    for sentences in data:\n",
    "\n",
    "        \n",
    "        sentences_of_indices = [token_indices[w] if w in token_indices.keys() else token_indices['UNK'] for w in sentences]\n",
    "\n",
    "        \n",
    "        if one_hot:\n",
    "            sentences_of_indices = np.eye(len(token_indices))[sentences_of_indices]\n",
    "\n",
    "        vectorized.append(sentences_of_indices)\n",
    "\n",
    "    return vectorized\n",
    "\n",
    "train_reviews_vectorized = vectorize_sentences(train_df.stemmed, token_indices)\n",
    "test_reviews_vectorized = vectorize_sentences(test_df.stemmed, token_indices)\n",
    "valid_reviews_vectorized = vectorize_sentences(valid_df.stemmed, token_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20e19e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[63, 173, 54, 125, 83]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_dim = [len(repr) for repr in train_reviews_vectorized]\n",
    "vectors_dim[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4bf9ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(samples, max_length):\n",
    "    \n",
    "    return torch.tensor([\n",
    "        sample[:max_length] + [1] * max(0, max_length - len(sample))\n",
    "        for sample in samples\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfd61b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 800\n",
    "train_reviews_vectorized = pad(train_reviews_vectorized, max_length = max_len)\n",
    "test_reviews_vectorized = pad(test_reviews_vectorized, max_length = max_len)\n",
    "valid_reviews_vectorized = pad(valid_reviews_vectorized, max_length = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52c67ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 192,   27,   33,  ...,    1,    1,    1],\n",
       "        [ 570,    2,  423,  ...,    1,    1,    1],\n",
       "        [   2,   13,    7,  ...,    1,    1,    1],\n",
       "        ...,\n",
       "        [  71,   18,   28,  ...,    1,    1,    1],\n",
       "        [   2,  902,   23,  ...,    1,    1,    1],\n",
       "        [ 214, 2689,  141,  ...,    1,    1,    1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fa86287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[800, 800, 800, 800, 800]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_dim = [len(repr) for repr in train_reviews_vectorized]\n",
    "vectors_dim[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "532e48c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples, labels):\n",
    "        self.samples = samples\n",
    "        self.labels = labels\n",
    "            \n",
    "    def __getitem__(self, k):\n",
    "        \n",
    "        return self.samples[k], self.labels[k]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c88362e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(len(indices_token), 100, padding_idx=1)\n",
    "        \n",
    "        conv1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=100, out_channels=128, kernel_size=3, padding=1),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool1d(kernel_size=2)\n",
    "        )\n",
    "        conv2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=128, out_channels=128, kernel_size=5, padding=2),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool1d(kernel_size=2)\n",
    "        )\n",
    "        conv3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=128, out_channels=128, kernel_size=5, padding=2),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool1d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        # 800 / 8\n",
    "        global_average = torch.nn.AvgPool1d(kernel_size=100, stride=100)\n",
    "\n",
    "        self.convolutions = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(p=0.4),\n",
    "            conv1, conv2, conv3, global_average\n",
    "        )\n",
    "\n",
    "        flatten = torch.nn.Flatten()\n",
    "        linear = torch.nn.Linear(in_features=128, out_features=2)\n",
    "        self.classifier = torch.nn.Sequential(flatten, linear)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        embeddings = self.embedding(input)\n",
    "        embeddings = embeddings.permute(0, 2, 1)\n",
    "        output = self.convolutions(embeddings)\n",
    "        output = self.classifier(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "273bdcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# instanțiem modelul\n",
    "model = Model().to(DEVICE)\n",
    "\n",
    "# Adam optimizer cu lr = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Cross Entropy loss\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# training dataset and dataloader\n",
    "# test dataset and dataloader\n",
    "train_ds = Dataset(train_reviews_vectorized, train_df.sentiment.tolist())\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_ds = Dataset(test_reviews_vectorized, test_df.sentiment.tolist())\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "valid_ds = Dataset(valid_reviews_vectorized, valid_df.sentiment.tolist())\n",
    "valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=64, shuffle=False)\n",
    "print(len(test_df.sentiment.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dab20c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1\n",
      "Validation accuracy: 0.8862\n",
      "Mean Loss: 0.0\n",
      "Epoch #2\n",
      "Validation accuracy: 0.883\n",
      "Mean Loss: 0.0\n",
      "Epoch #3\n",
      "Validation accuracy: 0.8578\n",
      "Mean Loss: 0.0\n",
      "Epoch #4\n",
      "Validation accuracy: 0.9008\n",
      "Mean Loss: 0.0\n",
      "Epoch #5\n",
      "Validation accuracy: 0.8986\n",
      "Mean Loss: 0.0\n",
      "Epoch #6\n",
      "Validation accuracy: 0.9052\n",
      "Mean Loss: 0.0\n",
      "Epoch #7\n",
      "Validation accuracy: 0.9056\n",
      "Mean Loss: 0.0\n",
      "Epoch #8\n",
      "Validation accuracy: 0.9016\n",
      "Mean Loss: 0.0\n",
      "Epoch #9\n",
      "Validation accuracy: 0.9046\n",
      "Mean Loss: 0.0\n",
      "Epoch #10\n",
      "Validation accuracy: 0.903\n",
      "Mean Loss: 0.0\n",
      "Best Validation accuracy: 0.9056\n",
      "Final Mean Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "for epoch_n in range(10):\n",
    "    print(f\"Epoch #{epoch_n + 1}\")\n",
    "    model.train()\n",
    "    for batch in train_dl:\n",
    "        model.zero_grad()\n",
    "\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.long().to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "\n",
    "        output = model(inputs)\n",
    "        loss = loss_fn(output, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    mean_loss = 0\n",
    "    model.eval()\n",
    "    all_predictions = torch.tensor([])\n",
    "    all_targets = torch.tensor([])\n",
    "    for batch in valid_dl:\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.long().to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "\n",
    "        predictions = output.argmax(1)\n",
    "        all_targets = torch.cat([all_targets, targets.detach().cpu()])\n",
    "        all_predictions = torch.cat([all_predictions, predictions.detach().cpu()])\n",
    "        \n",
    "    mean_loss /= len(valid_dl)\n",
    "    val_acc = (all_predictions == all_targets).float().mean().numpy()\n",
    "    print(\"Validation accuracy:\",val_acc)\n",
    "    print(\"Mean Loss:\", mean_loss)\n",
    "    if val_acc > best_val_acc:\n",
    "        torch.save(model.state_dict(), \"./model\")\n",
    "        best_val_acc = val_acc\n",
    "\n",
    "print(\"Best Validation accuracy:\", best_val_acc)\n",
    "print(\"Final Mean Loss:\", mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e840821e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./model_28Mar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "48841d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.909\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_predictions = torch.tensor([])\n",
    "all_targets = torch.tensor([])\n",
    "#print(test_df)\n",
    "for batch in test_dl:\n",
    "    inputs, targets = batch\n",
    "    inputs = inputs.long().to(DEVICE)\n",
    "    targets = targets.to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(inputs)\n",
    "\n",
    "    predictions = output.argmax(1)\n",
    "    #print(predictions)\n",
    "    all_targets = torch.cat([all_targets, targets.detach().cpu()])\n",
    "    all_predictions = torch.cat([all_predictions, predictions.detach().cpu()])\n",
    "\n",
    "val_acc = (all_predictions == all_targets).float().mean().numpy()\n",
    "print(\"Test Accuracy:\", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f8013aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4962\n",
      "5000\n",
      "5000\n",
      "tensor([False, False,  True,  ...,  True, False,  True])\n"
     ]
    }
   ],
   "source": [
    "ex_text_str = 'If you love Spider-Man then you will definitely love this film. Not only does \"Spider-Man: No Way Home\" have an amazing script but the characters are written perfectly. Not only will this blockbuster blow your socks off visually and emotionally but it will bring back a lot of needed nostalgia that is a breath of fresh air for Spider-Man fans of all generations.'\n",
    "\n",
    "d = {'review': [ex_text_str]}\n",
    "X_test = pd.DataFrame(data=d)\n",
    "X_test.review = df.review.apply(lower)\n",
    "X_test.review = df.review.apply(deleteHtmlTags)\n",
    "X_test.review = df.review.apply(unidecode)\n",
    "X_test.review = df.review.apply(deletePunctuation)\n",
    "X_test.review = df.review.apply(unescape)\n",
    "X_test.review = df.review.apply(deleteSpaces)\n",
    "X_test[\"stemmed\"] = X_test.review.apply(lambda x: [stemmer.stem(y) for y in x.split() if stemmer.stem(y) not in (stop)])\n",
    "X_test_vectorized=vectorize_sentences(X_test.stemmed, token_indices)\n",
    "X_test_vectorized = pad(X_test_vectorized, max_length = max_len)\n",
    "X_test_ds = Dataset(X_test_vectorized,[1])\n",
    "X_test_dl = torch.utils.data.DataLoader(test_ds, batch_size=1, shuffle=False)\n",
    "model.eval()\n",
    "all_predictions = torch.tensor([])\n",
    "all_targets = torch.tensor([])\n",
    "i=0\n",
    "#print(test_df)\n",
    "for batch in X_test_dl:\n",
    "    #print(i)\n",
    "    i=i+1\n",
    "    inputs, targets = batch\n",
    "    inputs = inputs.long().to(DEVICE)\n",
    "    targets = targets.to(DEVICE)\n",
    "    #print(\"targets\",targets)\n",
    "    with torch.no_grad():\n",
    "        output = model(inputs)\n",
    "\n",
    "    predictions = output.argmax(1)\n",
    "    \n",
    "    all_targets = torch.cat([all_targets, targets.detach().cpu()])\n",
    "    all_predictions = torch.cat([all_predictions, predictions.detach().cpu()])\n",
    "\n",
    "val_acc = (all_predictions == all_targets).float().mean().numpy()\n",
    "print(\"Test Accuracy:\", val_acc)\n",
    "print(len(all_predictions))\n",
    "print(len(all_targets))\n",
    "print(all_predictions==all_targets)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
